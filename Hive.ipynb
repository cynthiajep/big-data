{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Jka8DphrzJwU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a27fe515-1fa4-40a1-a4d8-99092d8f583d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpZDyl0U0yUz",
        "outputId": "56bfb5fd-2361-4040-ef9f-096da080bb2e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!wget https://dlcdn.apache.org/spark/spark-3.5.1/spark-3.5.1-bin-hadoop3.tgz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMHvt0zozNx5",
        "outputId": "02bf14d9-f9aa-4dc8-d1c9-dd019d8a66a9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-21 18:56:10--  https://dlcdn.apache.org/spark/spark-3.5.1/spark-3.5.1-bin-hadoop3.tgz\n",
            "Resolving dlcdn.apache.org (dlcdn.apache.org)... 151.101.2.132, 2a04:4e42::644\n",
            "Connecting to dlcdn.apache.org (dlcdn.apache.org)|151.101.2.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 400446614 (382M) [application/x-gzip]\n",
            "Saving to: ‘spark-3.5.1-bin-hadoop3.tgz’\n",
            "\n",
            "spark-3.5.1-bin-had 100%[===================>] 381.90M   183MB/s    in 2.1s    \n",
            "\n",
            "2024-03-21 18:56:12 (183 MB/s) - ‘spark-3.5.1-bin-hadoop3.tgz’ saved [400446614/400446614]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYNpN7c4zNux",
        "outputId": "8f04dde8-baed-4d21-a1ba-92690ae7aff5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: pyspark: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xvzf spark-3.5.1-bin-hadoop3.tgz"
      ],
      "metadata": {
        "id": "w_SZo8WRzNsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls/content/spark-3.5.1-bin-hadoop3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgtzXwzszNqW",
        "outputId": "1d03b288-c47f-4e2a-ca85-5e0f6e76fe8f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: ls/content/spark-3.5.1-bin-hadoop3: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo ls /content/spark-3.5.1-bin-hadoop3\n",
        "!pip install findspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQRpaSi0zNkF",
        "outputId": "ce8b5c70-18d6-4538-b3de-be4070739d9a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bin   data\tjars\t    LICENSE   NOTICE  R\t\t RELEASE  yarn\n",
            "conf  examples\tkubernetes  licenses  python  README.md  sbin\n",
            "Collecting findspark\n",
            "  Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
            "Installing collected packages: findspark\n",
            "Successfully installed findspark-2.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"SPARK_HOME\"]= \"/content/spark-3.5.1-bin-hadoop3\"\n",
        "\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "di4E24_r1xh0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n"
      ],
      "metadata": {
        "id": "kdaU3VZN1_nE"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Initialize SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"CSV-to-Hive Schema Matching\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Define the schema of the Hive table\n",
        "hive_table_schema = \"id INT, name STRING, age INT\"  # Example schema\n",
        "\n",
        "# Read the first few rows of the CSV file to infer its schema\n",
        "csv_file_path = \"/content/Top250.csv\"  # Specify the path to your CSV file\n",
        "df = spark.read.csv(csv_file_path, header=True, inferSchema=True)\n",
        "\n",
        "# Print the inferred schema of the CSV file\n",
        "print(\"Schema of the CSV file:\")\n",
        "df.printSchema()\n",
        "\n",
        "# Compare the inferred schema with the schema of the Hive table\n",
        "if df.schema.simpleString() == hive_table_schema:\n",
        "    print(\"CSV schema matches the schema of the Hive table.\")\n",
        "else:\n",
        "    print(\"CSV schema does not match the schema of the Hive table.\")\n",
        "\n",
        "# Stop the SparkSession\n",
        "spark.stop()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewTHrU-Oi7aW",
        "outputId": "4dcab44b-65a7-4b2d-c550-8760c6fd2e91"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Schema of the CSV file:\n",
            "root\n",
            " |-- Rank: integer (nullable = true)\n",
            " |-- Restaurant: string (nullable = true)\n",
            " |-- Content: string (nullable = true)\n",
            " |-- Sales: string (nullable = true)\n",
            " |-- YOY_Sales: string (nullable = true)\n",
            " |-- Units: string (nullable = true)\n",
            " |-- YOY_Units: string (nullable = true)\n",
            " |-- Headquarters: string (nullable = true)\n",
            " |-- Segment_Category: string (nullable = true)\n",
            "\n",
            "CSV schema does not match the schema of the Hive table.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType\n",
        "\n",
        "# Initialize SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Create Hive Tables from CSV\") \\\n",
        "    .config(\"spark.sql.warehouse.dir\", \"/user/hive/warehouse\") \\\n",
        "    .enableHiveSupport() \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Define schemas for each CSV file\n",
        "schema_csv1 = StructType([\n",
        "    StructField(\"Rank\", IntegerType(), True),\n",
        "    StructField(\"Restaurant\", StringType(), True),\n",
        "    StructField(\"Location\", StringType(), True),\n",
        "    StructField(\"Sales\", IntegerType(), True),\n",
        "    StructField(\"YOY_Sales\", StringType(), True),\n",
        "    StructField(\"Units\", IntegerType(), True),\n",
        "    StructField(\"YOY_Units\", StringType(), True),\n",
        "    StructField(\"Unit_Volume\", IntegerType(), True),\n",
        "    StructField(\"Franchising\", StringType(), True)\n",
        "])\n",
        "\n",
        "schema_csv2 = StructType([\n",
        "    StructField(\"Rank\", IntegerType(), True),\n",
        "    StructField(\"Restaurant\", StringType(), True),\n",
        "    StructField(\"Sales\", DoubleType(), True),\n",
        "    StructField(\"Average Check\", IntegerType(), True),\n",
        "    StructField(\"City\", StringType(), True),\n",
        "    StructField(\"State\", StringType(), True),\n",
        "    StructField(\"Meals Served\", DoubleType(), True)\n",
        "])\n",
        "\n",
        "schema_csv3 = StructType([\n",
        "    StructField(\"Rank\", IntegerType(), True),\n",
        "    StructField(\"Restaurant\", StringType(), True),\n",
        "    StructField(\"Content\", StringType(), True),\n",
        "    StructField(\"Sales\", StringType(), True),\n",
        "    StructField(\"YOY_Sales\", StringType(), True),\n",
        "    StructField(\"Units\", StringType(), True),\n",
        "    StructField(\"YOY_Units\", StringType(), True),\n",
        "    StructField(\"Headquarters\", StringType(), True),\n",
        "    StructField(\"Segment_Category\", StringType(), True)\n",
        "])\n",
        "\n",
        "# Load data from CSV files into DataFrames\n",
        "csv1_path = \"/content/Future50.csv\"  # Path to CSV file 1\n",
        "csv2_path = \"/content/Independence100.csv\"  # Path to CSV file 2\n",
        "csv3_path = \"/content/Top250.csv\"  # Path to CSV file 3\n",
        "\n",
        "df_csv1 = spark.read.csv(csv1_path, header=True, schema=schema_csv1)\n",
        "df_csv2 = spark.read.csv(csv2_path, header=True, schema=schema_csv2)\n",
        "df_csv3 = spark.read.csv(csv3_path, header=True, schema=schema_csv3)\n",
        "\n",
        "# Save DataFrames as Hive tables\n",
        "df_csv1.write.mode(\"overwrite\").saveAsTable(\"table_csv1\")\n",
        "df_csv2.write.mode(\"overwrite\").saveAsTable(\"table_csv2\")\n",
        "df_csv3.write.mode(\"overwrite\").saveAsTable(\"table_csv3\")\n",
        "\n",
        "# Stop the SparkSession\n",
        "spark.stop()\n"
      ],
      "metadata": {
        "id": "yQymalwaNTtY"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Query Hive Table\") \\\n",
        "    .config(\"spark.sql.warehouse.dir\", \"/user/hive/warehouse\") \\\n",
        "    .enableHiveSupport() \\\n",
        "    .getOrCreate()\n"
      ],
      "metadata": {
        "id": "TKBLWRSdpXa7"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Query 1: Retrieve the first 10 rows from table_csv1 with the highest sales\n",
        "query_1 = \"\"\"\n",
        "    SELECT *\n",
        "    FROM (\n",
        "        SELECT *, ROW_NUMBER() OVER (ORDER BY Sales DESC) AS rn\n",
        "        FROM table_csv1\n",
        "    ) t\n",
        "    WHERE rn <= 10\n",
        "\"\"\"\n",
        "result_1 = spark.sql(query_1)\n",
        "result_1.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClU55Dn2V_i5",
        "outputId": "26247b2f-b602-40ae-e4b8-2dba5ea68d5a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+--------------------+--------------------+-----+---------+-----+---------+-----------+-----------+---+\n",
            "|Rank|          Restaurant|            Location|Sales|YOY_Sales|Units|YOY_Units|Unit_Volume|Franchising| rn|\n",
            "+----+--------------------+--------------------+-----+---------+-----+---------+-----------+-----------+---+\n",
            "|   5|           Pokeworks|      Irvine, Calif.|   49|    77.1%|   50|    56.3%|       1210|        Yes|  1|\n",
            "|  41|Blue Sushi Sake G...|         Omaha, Neb.|   49|    19.5%|   14|    16.7%|       3500|         No|  2|\n",
            "|  14|      Bluestone Lane|      New York, N.Y.|   48|    33.0%|   48|    37.1%|       1175|         No|  3|\n",
            "|  46|         LA Crawfish|      McAllen, Texas|   48|    17.6%|   25|    13.6%|       2050|        Yes|  4|\n",
            "|  24|     Joe & The Juice|      New York, N.Y.|   47|    25.9%|   69|    25.5%|        760|        Yes|  5|\n",
            "|  42|      The Human Bean|       Medford, Ore.|   47|    19.0%|   97|    19.8%|        535|        Yes|  6|\n",
            "|  47|              &pizza|    Washington, D.C.|   45|    17.1%|   35|     9.4%|       1350|         No|  7|\n",
            "|  22|         Duck Donuts|  Mechanicsburg, Pa.|   44|    28.0%|   90|    16.9%|        530|        Yes|  8|\n",
            "|   2|         Clean Juice|     Charlotte, N.C.|   44|   121.9%|  105|    94.4%|        560|        Yes|  9|\n",
            "|  17|Ike's Love & Sand...|San Francisco, Ca...|   44|    30.8%|   71|    29.1%|        700|        Yes| 10|\n",
            "+----+--------------------+--------------------+-----+---------+-----+---------+-----------+-----------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Query 2: Count the total number of rows in table_csv2 and table_csv3 and calculate their sum\n",
        "query_2 = \"\"\"\n",
        "    SELECT 'table_csv2' AS Table, COUNT(*) AS Row_Count FROM table_csv2\n",
        "    UNION ALL\n",
        "    SELECT 'table_csv3' AS Table, COUNT(*) AS Row_Count FROM table_csv3\n",
        "\"\"\"\n",
        "result_2 = spark.sql(query_2)\n",
        "result_2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVQG2sGkcL7W",
        "outputId": "2b95e160-2e15-418e-c777-7eb61e2826bf"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---------+\n",
            "|     Table|Row_Count|\n",
            "+----------+---------+\n",
            "|table_csv2|      100|\n",
            "|table_csv3|      250|\n",
            "+----------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Query 3: Retrieve unique cities from table_csv2 along with their total sales\n",
        "query_3 = \"\"\"\n",
        "    SELECT City, COUNT(*) AS Total_Restaurants, SUM(Sales) AS Total_Sales\n",
        "    FROM table_csv2\n",
        "    GROUP BY City\n",
        "    ORDER BY Total_Sales DESC\n",
        "\"\"\"\n",
        "result_3 = spark.sql(query_3)\n",
        "result_3.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWadflNodP0q",
        "outputId": "7b01c360-9012-44b9-9bfe-dff191827e5b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+-----------------+------------+\n",
            "|          City|Total_Restaurants| Total_Sales|\n",
            "+--------------+-----------------+------------+\n",
            "|      New York|               21|4.06473807E8|\n",
            "|       Chicago|               15|2.68481978E8|\n",
            "|     Las Vegas|               11|2.05296684E8|\n",
            "|    Washington|                9|1.61413973E8|\n",
            "| San Francisco|                5| 6.7681136E7|\n",
            "|      Orlando |                2| 5.5047864E7|\n",
            "|         Miami|                3| 5.4481741E7|\n",
            "|Ft. Lauderdale|                2| 3.4301433E7|\n",
            "|  Indianapolis|                2| 3.4232062E7|\n",
            "|   Frankenmuth|                2| 3.3452435E7|\n",
            "|       Atlanta|                2|  3.278875E7|\n",
            "|     Nashville|                2| 2.7463743E7|\n",
            "|       Raleigh|                1|  2.426816E7|\n",
            "|   Miami Beach|                1|      2.38E7|\n",
            "|     Oak Brook|                1| 1.9831818E7|\n",
            "|       Houston|                1| 1.9530159E7|\n",
            "|  Philadelphia|                1| 1.9379153E7|\n",
            "|      Wheeling|                1| 1.8687601E7|\n",
            "|   Los Angeles|                1|    1.8521E7|\n",
            "|      Rosemont|                1| 1.8483056E7|\n",
            "+--------------+-----------------+------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Query 4: Analyze the distribution of restaurant sales by month from table_csv1\n",
        "query4_result = spark.sql(\"\"\"\n",
        "    SELECT Month, AVG(Sales) AS Avg_Sales\n",
        "    FROM (\n",
        "        SELECT SUBSTRING_INDEX(Location, '-', -1) AS Month, Sales\n",
        "        FROM table_csv1\n",
        "    ) t\n",
        "    GROUP BY Month\n",
        "    ORDER BY Month\n",
        "\"\"\")\n",
        "query4_result.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkZ9-fwYhwPj",
        "outputId": "2306ee81-e204-46fe-eae4-6ce9bdd6076a"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------------------+\n",
            "|               Month|         Avg_Sales|\n",
            "+--------------------+------------------+\n",
            "|Agoura Hills, Calif.|              31.0|\n",
            "|     Anaheim, Calif.|              27.0|\n",
            "|        Atlanta, Ga.|              29.0|\n",
            "|       Belmar,  N.J.|              39.0|\n",
            "|      Blue Bell, Pa.|              24.0|\n",
            "|     Charlotte, N.C.|              42.0|\n",
            "|      Columbus, Ohio|41.333333333333336|\n",
            "|        Conway, Ark.|              25.0|\n",
            "|       Denver, Colo.|              41.0|\n",
            "|         Doral, Fla.|              32.0|\n",
            "|        Douglas, Ga.|              22.0|\n",
            "|       Fairburn, Ga.|              38.0|\n",
            "|        Fairfax, Va.|              22.0|\n",
            "|       Frisco, Texas|              20.0|\n",
            "|Huntington Beach,...|              21.0|\n",
            "|      Irvine, Calif.|              49.0|\n",
            "|     Kettering, Ohio|              24.0|\n",
            "| Los Angeles, Calif.|              28.0|\n",
            "|     Louisville, Ky.|              29.0|\n",
            "|      McAllen, Texas|              48.0|\n",
            "+--------------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Query 5: Determine the top 3 restaurant chains with the highest average sales per unit from table_csv1\n",
        "query5_result = spark.sql(\"\"\"\n",
        "    SELECT Restaurant, AVG(Sales / Units) AS Avg_Sales_Per_Unit\n",
        "    FROM table_csv1\n",
        "    GROUP BY Restaurant\n",
        "    ORDER BY Avg_Sales_Per_Unit DESC\n",
        "    LIMIT 3\n",
        "\"\"\")\n",
        "query5_result.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bhal0e1khX9P",
        "outputId": "6c6c0a23-54eb-4585-daf4-a805b3c6b997"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------------------+\n",
            "|          Restaurant|Avg_Sales_Per_Unit|\n",
            "+--------------------+------------------+\n",
            "|     Bulla Gastrobar|               4.0|\n",
            "|            Boqueria| 3.857142857142857|\n",
            "|Blue Sushi Sake G...|               3.5|\n",
            "+--------------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Query 6: Calculate the average sales growth rate per restaurant from table_csv3\n",
        "query6_result = spark.sql(\"\"\"\n",
        "    SELECT Restaurant, AVG(CAST(REGEXP_REPLACE(YOY_Sales, '%', '') AS DOUBLE)) AS Avg_Sales_Growth_Rate\n",
        "    FROM table_csv3\n",
        "    GROUP BY Restaurant\n",
        "\"\"\")\n",
        "query6_result.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZPpwemfiKak",
        "outputId": "b723a474-ca51-4347-b1ec-5ee14289b6bb"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+---------------------+\n",
            "|          Restaurant|Avg_Sales_Growth_Rate|\n",
            "+--------------------+---------------------+\n",
            "|          Applebee's|                 -3.0|\n",
            "|    McAlister's Deli|                  7.0|\n",
            "|       Uncle Julio's|                 11.7|\n",
            "|       Buca di Beppo|                 -5.7|\n",
            "|  The Capital Grille|                  4.7|\n",
            "|            Cinnabon|                  5.6|\n",
            "|   Wetzel's Pretzels|                  3.9|\n",
            "|          Bojangles'|                  2.7|\n",
            "|Tropical Smoothie...|                 21.8|\n",
            "|         Red Lobster|                  1.6|\n",
            "|         O'Charley's|                 -7.6|\n",
            "|         Smashburger|                 -6.5|\n",
            "|Old Country Buffe...|                -18.8|\n",
            "|Captain D's Seafo...|                  3.1|\n",
            "|         Sonny's BBQ|                 -8.3|\n",
            "|  Buffalo Wild Wings|                 -0.1|\n",
            "|Islands Fine Burg...|                  0.9|\n",
            "|       Pret A Manger|                  4.7|\n",
            "|          Giordano's|                  5.5|\n",
            "|Checkers Drive-In...|                 -1.8|\n",
            "+--------------------+---------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Query 6: Retrieve restaurants with 'YOY_Sales' indicating growth and their corresponding segments from table_csv3\n",
        "query_6 = \"\"\"\n",
        "    SELECT t1.Restaurant, t1.Segment_Category\n",
        "    FROM table_csv3 t1\n",
        "    JOIN (\n",
        "        SELECT DISTINCT Restaurant\n",
        "        FROM table_csv3\n",
        "        WHERE YOY_Sales LIKE '%growth%'\n",
        "    ) t2 ON t1.Restaurant = t2.Restaurant\n",
        "\"\"\"\n",
        "result_6 = spark.sql(query_6)\n",
        "result_6.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ae7-3MmXe7MP",
        "outputId": "a0615c18-8567-450c-c2b9-58e4b39a174c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----------------+\n",
            "|Restaurant|Segment_Category|\n",
            "+----------+----------------+\n",
            "+----------+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Query 7: Find the restaurants with the highest increase in sales compared to the previous year in table_csv3\n",
        "query7_result = spark.sql(\"\"\"\n",
        "    SELECT Restaurant, (Sales - PREVIOUS_YEAR_SALES) AS Sales_Increase\n",
        "    FROM (\n",
        "        SELECT Restaurant, CAST(SUBSTRING(YOY_Sales, 1, LENGTH(YOY_Sales) - 1) AS FLOAT) / 100 * Sales AS PREVIOUS_YEAR_SALES, Sales\n",
        "        FROM table_csv3\n",
        "    ) t\n",
        "    ORDER BY Sales_Increase DESC\n",
        "    LIMIT 10\n",
        "\"\"\")\n",
        "query7_result.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmbH9gEwgaYM",
        "outputId": "763454c3-aaa5-4182-d5f7-bf0f36ec9004"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----------------+\n",
            "|  Restaurant|   Sales_Increase|\n",
            "+------------+-----------------+\n",
            "|  McDonald's|38431.81196146012|\n",
            "|   Starbucks|19541.31991844177|\n",
            "|      Subway|          10404.0|\n",
            "|   Taco Bell|         10276.63|\n",
            "| Burger King|9928.491995134355|\n",
            "| Chick-fil-A|           9848.4|\n",
            "|     Wendy's|9351.996018619537|\n",
            "|    Domino's|6557.963993282318|\n",
            "|Panera Bread|           5654.4|\n",
            "|   Pizza Hut| 5524.65199867487|\n",
            "+------------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Query 8: Retrieve restaurants with sales greater than the average sales of the previous year in table_csv2\n",
        "avg_sales_last_year = spark.sql(\"SELECT AVG(Sales) AS Avg_Sales_Last_Year FROM table_csv2\").collect()[0][0]\n",
        "query_8 = f\"\"\"\n",
        "    SELECT Restaurant\n",
        "    FROM table_csv2\n",
        "    WHERE Sales > {avg_sales_last_year}\n",
        "\"\"\"\n",
        "result_8 = spark.sql(query_8)\n",
        "result_8.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wBRkYnafD9e",
        "outputId": "81cc7f9b-f0d9-40e0-baae-ac0765ea01a3"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|          Restaurant|\n",
            "+--------------------+\n",
            "|Carmine's (Times ...|\n",
            "|The Boathouse Orl...|\n",
            "|    Old Ebbitt Grill|\n",
            "|LAVO Italian Rest...|\n",
            "|Bryant Park Grill...|\n",
            "|Gibsons Bar & Ste...|\n",
            "|Top of the World ...|\n",
            "|         Maple & Ash|\n",
            "|           Balthazar|\n",
            "|   Smith & Wollensky|\n",
            "|          Angus Barn|\n",
            "|           Prime 112|\n",
            "|Joe's Seafood, Pr...|\n",
            "|Junior's (Times S...|\n",
            "|        The Hamilton|\n",
            "|Joe's Seafood, Pr...|\n",
            "|Joe's Seafood, Pr...|\n",
            "|      Gibsons Italia|\n",
            "|              Komodo|\n",
            "|            Buddakan|\n",
            "+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Query 9: Retrieve top 5 restaurants with the highest sales from table_csv1 along with their units sold\n",
        "query_9 = \"\"\"\n",
        "    SELECT t1.Restaurant, t1.Sales, t1.Units\n",
        "    FROM table_csv1 t1\n",
        "    JOIN (\n",
        "        SELECT Restaurant, Sales\n",
        "        FROM table_csv1\n",
        "        ORDER BY Sales DESC\n",
        "        LIMIT 5\n",
        "    ) t2 ON t1.Restaurant = t2.Restaurant\n",
        "\"\"\"\n",
        "result_9 = spark.sql(query_9)\n",
        "result_9.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bru9v-xfuo4",
        "outputId": "4453f6dc-ebbe-44e5-ecc2-bda5bd5cea24"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+-----+\n",
            "|          Restaurant|Sales|Units|\n",
            "+--------------------+-----+-----+\n",
            "|           Pokeworks|   49|   50|\n",
            "|      Bluestone Lane|   48|   48|\n",
            "|     Joe & The Juice|   47|   69|\n",
            "|Blue Sushi Sake G...|   49|   14|\n",
            "|         LA Crawfish|   48|   25|\n",
            "+--------------------+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Query 10: Retrieve restaurants with 'Franchising' status from table_csv1 and their corresponding locations\n",
        "query_10 = \"\"\"\n",
        "    SELECT t1.Restaurant, t1.Location\n",
        "    FROM table_csv1 t1\n",
        "    JOIN (\n",
        "        SELECT DISTINCT Restaurant\n",
        "        FROM table_csv1\n",
        "        WHERE Franchising IS NOT NULL\n",
        "    ) t2 ON t1.Restaurant = t2.Restaurant\n",
        "\"\"\"\n",
        "result_10 = spark.sql(query_10)\n",
        "result_10.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0Jtf-_ifwYK",
        "outputId": "af672469-a9ac-4236-eb49-bac092ee5b55"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+\n",
            "|          Restaurant|            Location|\n",
            "+--------------------+--------------------+\n",
            "|          Evergreens|      Seattle, Wash.|\n",
            "|         Clean Juice|     Charlotte, N.C.|\n",
            "|            Slapfish|Huntington Beach,...|\n",
            "|          Clean Eatz|    Wilmington, N.C.|\n",
            "|           Pokeworks|      Irvine, Calif.|\n",
            "|         Playa Bowls|       Belmar,  N.J.|\n",
            "|    The Simple Greek|      Blue Bell, Pa.|\n",
            "|           Melt Shop|      New York, N.Y.|\n",
            "|          Creamistry|Yorba Linda,  Calif.|\n",
            "|Joella's Hot Chicken|     Louisville, Ky.|\n",
            "|       Eggs Up Grill|   Spartanburg, S.C.|\n",
            "|            Dog Haus|    Pasadena, Calif.|\n",
            "|    Teriyaki Madness|       Denver, Colo.|\n",
            "|      Bluestone Lane|      New York, N.Y.|\n",
            "|   Original ChopShop|        Plano, Texas|\n",
            "|   Rapid Fired Pizza|     Kettering, Ohio|\n",
            "|Ike's Love & Sand...|San Francisco, Ca...|\n",
            "|      Vitality Bowls|   San Ramon, Calif.|\n",
            "|Hawkers Asian Str...|       Orlando, Fla.|\n",
            "|Maple Street Bisc...|   Orange Park, Fla.|\n",
            "+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    }
  ]
}